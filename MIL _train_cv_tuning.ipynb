{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff2d5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import mymodel.model as model\n",
    "import numpy as np\n",
    "import glob\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import mydataset.mydataset as mydataset\n",
    "import utils as utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d8e582",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def seed_torch(seed=7):\n",
    "    random.seed(seed)\n",
    "    # os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed) # if you are using multi-GPU.\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748e8ffe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run(args):\n",
    "    net = getattr(model, args['arch'])(inputd=args['inputd'])\n",
    "\n",
    "    parameters = list(filter(lambda p: p.requires_grad, net.parameters()))\n",
    "\n",
    "    optimizer = torch.optim.Adam(parameters, lr=args['lr'], weight_decay=args['reg'])\n",
    "    #scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args['epochs'], eta_min=0, last_epoch=-1, verbose=True)\n",
    "\n",
    "    train_dataset = getattr(mydataset, args['data'])(train='train', r=args['r'], k=args['k'], keys=args['keys'], split=args['split'])\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=args['batch_size'], shuffle=True,\n",
    "        num_workers=32, pin_memory=True)\n",
    "    \n",
    "    \"\"\"\n",
    "    labels = np.array([])\n",
    "    for _, label in train_loader:\n",
    "        labels = np.append(labels, label.item())\n",
    "    \n",
    "    #print(labels, np.argwhere(labels == 1))\n",
    "    pos_weight = len(np.argwhere(labels == 0)) / len(np.argwhere(labels == 1))\n",
    "    \"\"\"\n",
    "    \n",
    "    # BCE loss, Adam opt, POS_Weight computed using above method (Harcoded to reduce time)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight = torch.tensor(args['posRate'])).cuda('cuda')\n",
    "    \n",
    "    val_dataset = getattr(mydataset, args['data'])(train='val', r=args['r'], k=args['k'], keys=args['keys'], split=args['split'])\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=args['batch_size'], shuffle=False,\n",
    "        num_workers=32, pin_memory=True)\n",
    "\n",
    "    test_dataset = getattr(mydataset, args['data'])(train='test', r=args['r'], k=args['k'], keys=args['keys'], split=args['split'])\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size=args['batch_size'], shuffle=False,\n",
    "        num_workers=32, pin_memory=True)\n",
    "\n",
    "\n",
    "    net.cuda()\n",
    "    writer = SummaryWriter(os.path.join(args['save'], time.strftime(\"%Y-%m-%d-%H:%M:%S\", time.gmtime())))\n",
    "    \n",
    "    # set-up early stopping\n",
    "    EarlyStopping = utils.EarlyStopping(save_dir=args['save'], args=args)\n",
    "    monitor_values = {'acc':0, 'auc':1, 'loss':4}\n",
    "    monitor_idx = monitor_values[args['monitor']]\n",
    "    bestValidationMetrics = None\n",
    "    \n",
    "    for epoch in range(args['epochs']):\n",
    "        \n",
    "        # train for one epoch\n",
    "        train(train_loader, net, criterion, optimizer, epoch, args, writer)\n",
    "\n",
    "        # evaluate on validation set (acc, auc, sen, spe, loss)\n",
    "        metrics = validate(val_loader, net, epoch, criterion, args, writer, 'val')\n",
    "\n",
    "        # early stopping based on validation performance\n",
    "        EarlyStopping(epoch, metrics[monitor_idx], net, optimizer)\n",
    "\n",
    "        # evaluate on testing set\n",
    "        if EarlyStopping.early_stop:\n",
    "            _ = validate(test_loader, net, epoch, criterion, args, writer, 'test')\n",
    "            print('****Early stop at epoch:{}'.format(epoch-args['patience']))\n",
    "            break\n",
    "        else:\n",
    "            if EarlyStopping.counter == 0:\n",
    "                bestValidationMetrics = metrics\n",
    "                best_metrics = validate(test_loader, net, epoch, criterion, args, writer, 'test')\n",
    "                best_epoch = epoch\n",
    "            else:\n",
    "                _ = validate(test_loader, net, epoch, criterion, args, writer, 'test')\n",
    "        #print(\"Last LR :\", scheduler.get_last_lr())\n",
    "        #scheduler.step()\n",
    "    print('****testing result: epoch: {}, acc: {}, auc: {}, sen: {}, spe: {}, loss: {}'.format(best_epoch, best_metrics[0], best_metrics[1], \\\n",
    "    best_metrics[2], best_metrics[3], best_metrics[4]))\n",
    "    return best_metrics, bestValidationMetrics\n",
    "\n",
    "def train(train_loader, model, criterion,  optimizer, epoch, args, writer):\n",
    "    losses = utils.AverageMeter('Loss', ':.4e')\n",
    "\n",
    "    progress = utils.ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [losses],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        images = images.cuda()\n",
    "        target = target.cuda().float()\n",
    "\n",
    "        output, _ = model(images)\n",
    "        output = output.view(-1).float()\n",
    "        if i == 0:\n",
    "            outputs = output\n",
    "            targets = target\n",
    "        else:\n",
    "            outputs = torch.cat((outputs, output), 0)\n",
    "            targets = torch.cat((targets, target), 0)\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "        if args['sd']:\n",
    "            loss += (args['sd']/2) * torch.norm(output).pow(2)\n",
    "        \n",
    "        losses.update(loss.item(), images.size(0))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % args['freq'] == 0:\n",
    "            progress.display(i)\n",
    "\n",
    "    acc, sen, spe = utils.accuracy(outputs, targets, args['threshold'], False)\n",
    "\n",
    "    if writer:\n",
    "        writer.add_scalar(\"Loss/train\", losses.avg, epoch)\n",
    "        writer.add_scalar(\"Accuracy/train\", acc, epoch)\n",
    "        writer.add_scalar(\"sen/train\", sen, epoch)\n",
    "        writer.add_scalar(\"spe/train\", spe, epoch)\n",
    "\n",
    "\n",
    "def validate(val_loader, model, epoch, criterion, args, writer, val='val'):\n",
    "    losses = utils.AverageMeter('Loss', ':.4e')\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (images, target) in enumerate(val_loader):    \n",
    "            images = images.cuda()\n",
    "            target = target.cuda().float()\n",
    "\n",
    "            output, _ = model(images)\n",
    "            output = output.view(-1).float()\n",
    "            if i == 0:\n",
    "                outputs = output\n",
    "                targets = target\n",
    "            else:\n",
    "                outputs = torch.cat((outputs, output), 0)\n",
    "                targets = torch.cat((targets, target), 0)\n",
    "            loss = criterion(output, target)\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "\n",
    "    acc, sen, spe, auc = utils.accuracy(outputs, targets, args['threshold'])\n",
    "\n",
    "    if val == 'val':\n",
    "        print(' **Validation Acc {acc:.3f} sen {sen:.3f} spe {spe:.3f} AUC {auc:.3f} LOSS {loss:.3f}'\n",
    "            .format(acc=acc, sen=sen, spe=spe, auc=auc, loss=losses.avg))\n",
    "    else:\n",
    "        print(' ***Testing Acc {acc:.3f} sen {sen:.3f} spe {spe:.3f} AUC {auc:.3f} LOSS {loss:.3f}'\n",
    "            .format(acc=acc, sen=sen, spe=spe, auc=auc, loss=losses.avg))\n",
    "\n",
    "    if writer:\n",
    "        writer.add_scalar(\"Loss/\"+val, losses.avg, epoch)\n",
    "        writer.add_scalar(\"Accuracy/\"+val, acc, epoch)\n",
    "        writer.add_scalar(\"sen/\"+val, sen, epoch)\n",
    "        writer.add_scalar(\"spe/\"+val, spe, epoch)\n",
    "        writer.add_scalar(\"auc/\"+val, auc, epoch)\n",
    "\n",
    "    return acc, auc, sen, spe, losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c4db32",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'model' : '',\n",
    "    'arch' : 'attmil_ctranspath',\n",
    "    'data' : 'cam16_curcos',\n",
    "    'split': 42,\n",
    "    'batch_size': 1,\n",
    "    'epochs': 100,\n",
    "    'inputd': 1024,\n",
    "    'code': 'cam_17',\n",
    "    'threshold': 0.5,\n",
    "    'lr': 2e-4,\n",
    "    'reg': 1e-5,\n",
    "    'freq': 100,\n",
    "    'pretrained': \"\",\n",
    "    'patience': 10,\n",
    "    'stop_epoch': 30,\n",
    "    'monitor': 'loss',\n",
    "    'sd': None,\n",
    "    'r': 0.10,\n",
    "    'k': -1,\n",
    "    'posRate': 1.45,\n",
    "    'keys': 'cam16_indexes_dict_CompareEachFE_non_redundant_threshold_0.95_mean_5.npy'#'indexes_dict_all.npy'\n",
    "}\n",
    "\n",
    "if args['sd']:\n",
    "    print('spectrum decoupling')  \n",
    "\n",
    "save_code = './CM16/results/runs/'+args[\"code\"]\n",
    "if not os.path.exists(save_code):\n",
    "    os.mkdir(save_code)\n",
    "        \n",
    "for split in range(42, 47): \n",
    "    \n",
    "    args[\"split\"] = split\n",
    "    save_dir = save_code + '/' + str(args[\"split\"])\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir) \n",
    "        \n",
    "    testRes = {'k':[], 'r':[], 'auc':[], 'acc':[], 'sen':[], 'spe': []}\n",
    "    validationRes = {'k':[], 'r':[], 'auc':[], 'acc':[], 'sen':[], 'spe': []}\n",
    "    \n",
    "    for i in [[-1, \"max\"], [-5, \"mean_5\"], [-10, \"mean_10\"], [-20, \"mean_20\"], [-50, \"mean_50\"], [-100, \"mean_100\"], [-150, \"mean_150\"]]:   \n",
    "        for j in [0.1, 0.2, 0.3, 0.5, 0.7]:\n",
    "            \n",
    "            seed_torch(7)\n",
    "            \n",
    "            print(i[0], \"_\", j)\n",
    "            args[\"k\"] = i[0]\n",
    "            args[\"r\"] = j\n",
    "            args[\"keys\"] = \"indexes_dict_CompareEachFE_non_redundant_threshold_0.95_{}.npy\".format(i[1])\n",
    "            args[\"save\"] = os.path.join(save_dir, str(-1*i[0])+'_'+str(j))\n",
    "        \n",
    "            testMetrics, validationMetrics = run(args)\n",
    "            \n",
    "            testRes['k'].append(i[1])\n",
    "            testRes['r'].append(j)\n",
    "            testRes['auc'].append(testMetrics[1])\n",
    "            testRes['acc'].append(testMetrics[0])\n",
    "            testRes['sen'].append(testMetrics[2])\n",
    "            testRes['spe'].append(testMetrics[3])\n",
    "            \n",
    "            validationRes['k'].append(i[1])\n",
    "            validationRes['r'].append(j)\n",
    "            validationRes['auc'].append(validationMetrics[1])\n",
    "            validationRes['acc'].append(validationMetrics[0])\n",
    "            validationRes['sen'].append(validationMetrics[2])\n",
    "            validationRes['spe'].append(validationMetrics[3])\n",
    "            \n",
    "    df = pd.DataFrame(testRes)\n",
    "    df.to_csv(os.path.join(save_dir, 'testResults.csv'))\n",
    "    \n",
    "    df = pd.DataFrame(validationRes)\n",
    "    df.to_csv(os.path.join(save_dir, 'validationResults.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
